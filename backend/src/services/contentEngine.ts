import OpenAI from "openai";
import FormData from "form-data";
import sharp from "sharp";
import axios from "axios";
import { v2 as cloudinary } from "cloudinary";
import { FalService } from "./fal";
import { dbService as airtableService, Post, Asset } from "./database";
import { GeminiService } from "./gemini";
import { ROIService } from "./roi";

// Configuration
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

cloudinary.config({
  cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
  api_key: process.env.CLOUDINARY_API_KEY,
  api_secret: process.env.CLOUDINARY_API_SECRET,
});

const AI_TIMEOUT = 120000;
const VIDEO_UPLOAD_TIMEOUT = 600000;

// Kie AI Config
const KIE_BASE_URL = "https://api.kie.ai/api/v1";
const KIE_API_KEY = process.env.KIE_AI_API_KEY;

// FAL AI Config (Kling 2.5 Turbo)
const FAL_KEY = process.env.FAL_KEY;
const FAL_BASE_PATH = "https://queue.fal.run/fal-ai/kling-video/v2.5-turbo";

const getOptimizedUrl = (url: string) => {
  if (!url || typeof url !== "string") return url;
  if (url.includes("cloudinary.com") && url.includes("/upload/")) {
    return url.replace("/upload/", "/upload/w_1280,c_limit,q_auto,f_jpg/");
  }
  return url;
};

// === HELPER 1: BLACK FILL FALLBACK ===
const resizeWithBlurFill = async (
  buffer: Buffer,
  width: number,
  height: number
): Promise<Buffer> => {
  try {
    const background = await sharp({
      create: {
        width: width,
        height: height,
        channels: 4,
        background: { r: 0, g: 0, b: 0, alpha: 255 }, // Solid Black
      },
    })
      .png()
      .toBuffer();

    const foreground = await sharp(buffer)
      .resize({
        width: width,
        height: height,
        fit: "contain",
        background: { r: 0, g: 0, b: 0, alpha: 0 },
      })
      .toBuffer();

    return await sharp(background)
      .composite([{ input: foreground, gravity: "center" }])
      .toFormat("jpeg", { quality: 95 })
      .toBuffer();
  } catch (e) {
    return await sharp(buffer)
      .resize(width, height, { fit: "cover", position: "center" })
      .toFormat("jpeg")
      .toBuffer();
  }
};

// === HELPER 2: STRICT CROP ===
const resizeStrict = async (
  buffer: Buffer,
  width: number,
  height: number
): Promise<Buffer> => {
  console.log("üìè Using Strict Center Crop (No AI) for Consistency");
  return await sharp(buffer)
    .resize(width, height, {
      fit: "cover",
      position: "center",
    })
    .toFormat("jpeg", { quality: 95 })
    .toBuffer();
};

// === HELPER 3: GEMINI RESIZE (Black Bar Removal) ===
const resizeWithGemini = async (
  originalBuffer: Buffer,
  targetWidth: number,
  targetHeight: number
): Promise<Buffer> => {
  try {
    console.log(
      `‚ú® Gemini 3 Pro: Outpainting ${targetWidth}x${targetHeight}...`
    );

    const backgroundGuide = await sharp({
      create: {
        width: targetWidth,
        height: targetHeight,
        channels: 4,
        background: { r: 0, g: 0, b: 0, alpha: 255 },
      },
    })
      .png()
      .toBuffer();

    const compositeBuffer = await sharp(backgroundGuide)
      .composite([
        {
          input: await sharp(originalBuffer)
            .resize({ width: targetWidth, height: targetHeight, fit: "inside" })
            .toBuffer(),
          gravity: "center",
        },
      ])
      .png()
      .toBuffer();

    const isPortrait = targetHeight > targetWidth;
    const direction = isPortrait ? "vertical" : "horizontal";

    const fullPrompt = `
    TASK: Image Extension (Outpainting).
    INPUT: An image with a sharp central subject and BLACK ${direction} bars.
    INSTRUCTIONS:
    1. REMOVE THE BLACK BARS: The black areas are empty space. Paint over them completely with high-definition details.
    2. SEAMLESS EXTENSION: Match lighting, texture, and style.
    3. NO LETTERBOXING: Final output must be full-screen.
    4. PRESERVE CENTER: Do not modify the central subject.
    `;

    return await GeminiService.generateOrEditImage({
      prompt: fullPrompt,
      aspectRatio: isPortrait ? "9:16" : "16:9",
      referenceImages: [compositeBuffer],
      modelType: "quality",
    });
  } catch (error: any) {
    console.error("‚ùå Gemini Resize Error:", error.message);
    throw error;
  }
};

export const contentEngine = {
  // ‚úÖ NEW: Upload Raw (No Resizing)
  async uploadRawAsset(fileBuffer: Buffer, userId: string) {
    try {
      // 1. Get Dimensions just for the DB record (we don't change the image)
      const metadata = await sharp(fileBuffer).metadata();
      const width = metadata.width || 1000;
      const height = metadata.height || 1000;

      // Calculate a rough ratio string for the UI grid
      let ratio = "16:9";
      if (Math.abs(width / height - 1) < 0.1) ratio = "1:1";
      else if (height > width) ratio = "9:16";

      console.log(`üöÄ Uploading Raw Asset: ${width}x${height} (${ratio})`);

      // 2. Upload ORIGINAL buffer to Cloudinary
      const url = await this.uploadToCloudinary(
        fileBuffer,
        `raw_${userId}_${Date.now()}`,
        userId,
        "Raw Upload",
        "image"
      );

      // 3. Save to DB with a flag or just the detected ratio
      // We explicitly pass the calculated ratio so it fits nicely in the Asset Library grid later
      return await airtableService.createAsset(userId, url, ratio as any);
    } catch (e: any) {
      console.error("Raw Upload Failed:", e.message);
      throw e;
    }
  },
  // === BATCH ASSET PROCESSOR ===
  async processAndSaveAsset(
    fileBuffer: Buffer,
    userId: string,
    targetAspectRatio: "16:9" | "9:16"
  ) {
    try {
      const targetWidth = targetAspectRatio === "16:9" ? 1280 : 720;
      const targetHeight = targetAspectRatio === "16:9" ? 720 : 1280;

      const metadata = await sharp(fileBuffer).metadata();
      const sourceAR = (metadata.width || 1) / (metadata.height || 1);
      const targetRatioNum = targetWidth / targetHeight;

      const isMatch = Math.abs(sourceAR - targetRatioNum) < 0.15;

      let processedBuffer: Buffer;

      if (isMatch) {
        processedBuffer = await resizeStrict(
          fileBuffer,
          targetWidth,
          targetHeight
        );
      } else {
        try {
          processedBuffer = await resizeWithGemini(
            fileBuffer,
            targetWidth,
            targetHeight
          );
        } catch (e) {
          processedBuffer = await resizeWithBlurFill(
            fileBuffer,
            targetWidth,
            targetHeight
          );
        }
      }

      const url = await this.uploadToCloudinary(
        processedBuffer,
        `asset_${userId}_${Date.now()}`,
        userId,
        "Processed Asset",
        "image"
      );

      return await airtableService.createAsset(userId, url, targetAspectRatio);
    } catch (e: any) {
      console.error("Asset Processing Failed:", e.message);
      throw e;
    }
  },

  // === MOVE POST MEDIA TO ASSET ===
  async copyPostMediaToAsset(postId: string, userId: string): Promise<Asset> {
    const post = await airtableService.getPostById(postId);
    if (!post || !post.mediaUrl) throw new Error("Post has no media");

    // If it's a carousel (JSON array), pick the first image
    let targetUrl = post.mediaUrl;
    try {
      const parsed = JSON.parse(post.mediaUrl);
      if (Array.isArray(parsed)) targetUrl = parsed[0];
    } catch (e) {}

    // üõ†Ô∏è FIX: Robust Aspect Ratio Detection
    const params = post.generationParams as any;
    const rawRatio = params?.aspectRatio;

    let dbAspectRatio = "16:9"; // Default fallback

    if (rawRatio === "landscape" || rawRatio === "16:9") {
      dbAspectRatio = "16:9";
    } else if (rawRatio === "portrait" || rawRatio === "9:16") {
      dbAspectRatio = "9:16";
    } else if (rawRatio === "square" || rawRatio === "1:1") {
      dbAspectRatio = "1:1"; // This will show up in the "Magic / Raw" tab
    } else if (rawRatio === "original") {
      dbAspectRatio = "original";
    }

    // Create Asset entry pointing to existing Cloudinary URL
    return await airtableService.createAsset(userId, targetUrl, dbAspectRatio);
  },

  // === DRIFT EDIT ===
  async processDriftEdit(
    userId: string,
    assetUrl: string,
    horizontal: number,
    vertical: number,
    zoom: number
  ) {
    try {
      // 1. Generate via FAL
      const buffer = await FalService.generateDriftAngle({
        imageUrl: getOptimizedUrl(assetUrl),
        horizontalAngle: horizontal,
        verticalAngle: vertical,
        zoom: zoom,
      });

      // 2. Upload to Cloudinary
      const newUrl = await this.uploadToCloudinary(
        buffer,
        `drift_${userId}_${Date.now()}`,
        userId,
        `Drift: H${horizontal} V${vertical} Z${zoom}`,
        "image"
      );

      // 3. Save as Asset (Original Ratio)
      // Drift maintains aspect ratio usually, or outputs square depending on model defaults.
      // We will mark it as "original" to be safe.
      return await airtableService.createAsset(userId, newUrl, "original");
    } catch (e: any) {
      throw new Error(`Drift failed: ${e.message}`);
    }
  },

  // === EDIT ASSET (Updated for Standard/Pro & Raw) ===
  async editAsset(
    originalAssetUrl: string,
    prompt: string,
    userId: string,
    aspectRatio: "16:9" | "9:16" | "original",
    referenceUrl?: string,
    mode: "standard" | "pro" = "pro" // üëà Added Mode Flag (Default to Pro)
  ): Promise<Asset> {
    try {
      console.log(`üé® Editing asset for ${userId} [${mode}]: "${prompt}"`);

      // 1. Prepare Inputs
      const imageResponse = await axios.get(getOptimizedUrl(originalAssetUrl), {
        responseType: "arraybuffer",
      });
      const inputBuffers = [Buffer.from(imageResponse.data)];

      let finalPrompt = prompt;

      // 2. Map frontend mode to GeminiService modelType
      // Standard -> Speed (Gemini 2.5 Flash)
      // Pro -> Quality (Gemini 3 Pro)
      const modelType = mode === "standard" ? "speed" : "quality";

      // 3. CHECK REFERENCE
      if (referenceUrl) {
        console.log("üîó Attaching Reference Image...");
        const refRes = await axios.get(getOptimizedUrl(referenceUrl), {
          responseType: "arraybuffer",
        });
        inputBuffers.push(Buffer.from(refRes.data));

        // Enhanced prompt logic for Pro mode with reference
        if (mode === "pro") {
          finalPrompt = `
TASK: ${prompt}
INPUT ANALYSIS:
- IMAGE 1 (Context): The MAIN SUBJECT.
- IMAGE 2 (Reference): The TARGET VIEWPOINT/ANGLE or STYLE REFERENCE.
INSTRUCTIONS:
1. SUBJECT LOCK: Strictly preserve the visual identity, colors, and structure of Subject 1.
2. TRANSFORMATION: Apply the style, angle, or modifications requested using Image 2 as a guide.
3. OUTPUT: High-fidelity image.
            `;
        }
      }

      // 4. Execute via SDK
      const editedBuffer = await GeminiService.generateOrEditImage({
        prompt: finalPrompt,
        // If aspectRatio is "original", GeminiService handles it by not sending imageConfig
        aspectRatio: aspectRatio === "original" ? "original" : aspectRatio,
        referenceImages: inputBuffers,
        modelType: modelType,
        useGrounding: mode === "pro", // Only use Google Search in Pro mode
      });

      // 5. Upload Result
      const newUrl = await this.uploadToCloudinary(
        editedBuffer,
        `edited_${userId}_${Date.now()}`,
        userId,
        `Edited: ${prompt}`,
        "image"
      );

      // 6. Save to Database
      return await airtableService.createAsset(userId, newUrl, aspectRatio);
    } catch (e: any) {
      console.error("Asset Edit Failed:", e.message);
      throw new Error(`Edit failed: ${e.message}`);
    }
  },

  // ===========================================================================
  // 1. INITIATE VIDEO GENERATION
  // ===========================================================================
  async startVideoGeneration(postId: string, finalPrompt: string, params: any) {
    console.log(`üé¨ Video Gen for ${postId} | Model Input: ${params.model}`);

    const isKie = params.model.includes("kie");
    const isKling = params.model.includes("kling");
    const isOpenAI = !isKie && !isKling;
    const isPro = params.model.includes("pro") || params.model.includes("Pro");

    try {
      let finalInputImageBuffer: Buffer | undefined;
      let targetWidth = 1280;
      let targetHeight = 720;
      const isPortrait =
        params.aspectRatio === "portrait" || params.aspectRatio === "9:16";

      if (params.size) {
        const [w, h] = params.size.split("x");
        targetWidth = parseInt(w);
        targetHeight = parseInt(h);
      } else if (params.resolution) {
        if (params.resolution === "1080p") {
          targetWidth = isPortrait ? 1080 : 1920;
          targetHeight = isPortrait ? 1920 : 1080;
        } else {
          targetWidth = isPortrait ? 720 : 1280;
          targetHeight = isPortrait ? 1280 : 720;
        }
      }

      const rawRefUrl =
        params.imageReferences && params.imageReferences.length > 0
          ? params.imageReferences[0]
          : params.imageReference;
      const refUrl = getOptimizedUrl(rawRefUrl);

      if (refUrl && params.hasReferenceImage) {
        try {
          const imageResponse = await axios.get(refUrl, {
            responseType: "arraybuffer",
            timeout: 60000,
          });
          const originalImageBuffer = Buffer.from(imageResponse.data);
          const metadata = await sharp(originalImageBuffer).metadata();
          const sourceAR = (metadata.width || 1) / (metadata.height || 1);
          const targetAR = targetWidth / targetHeight;

          if (Math.abs(sourceAR - targetAR) < 0.05) {
            finalInputImageBuffer = await resizeStrict(
              originalImageBuffer,
              targetWidth,
              targetHeight
            );
          } else {
            try {
              finalInputImageBuffer = await resizeWithGemini(
                originalImageBuffer,
                targetWidth,
                targetHeight
              );
            } catch (geminiError) {
              finalInputImageBuffer = await resizeWithBlurFill(
                originalImageBuffer,
                targetWidth,
                targetHeight
              );
            }
          }
        } catch (e: any) {
          console.error("‚ùå Image Processing Failed:", e.message);
        }
      }

      let externalId = "";
      let statusUrl = "";
      let provider = "";

      if (isKie) {
        provider = "kie";
        let kieInputUrl = "";
        let isImageToVideo = false;
        if (finalInputImageBuffer) {
          kieInputUrl = await this.uploadToCloudinary(
            finalInputImageBuffer,
            `${postId}_input`,
            params.userId,
            "Kie Input",
            "image"
          );
          isImageToVideo = true;
        }
        const baseModel = isPro ? "sora-2-pro" : "sora-2";
        const mode = isImageToVideo ? "image-to-video" : "text-to-video";
        const kiePayload: any = {
          model: `${baseModel}-${mode}`,
          input: {
            prompt: finalPrompt,
            aspect_ratio: isPortrait ? "portrait" : "landscape",
            n_frames: params.duration
              ? params.duration.toString().replace("s", "")
              : "10",
            remove_watermark: true,
          },
        };
        if (isImageToVideo) kiePayload.input.image_urls = [kieInputUrl];

        const kieRes = await axios.post(
          `${KIE_BASE_URL}/jobs/createTask`,
          kiePayload,
          { headers: { Authorization: `Bearer ${KIE_API_KEY}` } }
        );
        if (kieRes.data.code !== 200)
          throw new Error(`Kie Error: ${JSON.stringify(kieRes.data)}`);
        externalId = kieRes.data.data.taskId;
      }

      // KLING Branch
      else if (isKling) {
        provider = "kling";
        let klingInputUrl = "";
        let klingTailUrl = "";
        let isImageToVideo = false;

        if (finalInputImageBuffer) {
          // Upload Start Frame
          klingInputUrl = await this.uploadToCloudinary(
            finalInputImageBuffer,
            `${postId}_kling_start`,
            params.userId,
            "Kling Start",
            "image"
          );
          isImageToVideo = true;

          // Check for End Frame (Tail)
          if (params.imageReferences && params.imageReferences.length > 1) {
            try {
              const tailRaw = getOptimizedUrl(params.imageReferences[1]);
              const tailResp = await axios.get(tailRaw, {
                responseType: "arraybuffer",
              });
              const tailOriginalBuffer = Buffer.from(tailResp.data);

              // Resize Tail logic (simplified for brevity, assumes helpers exist)
              const meta = await sharp(tailOriginalBuffer).metadata();
              const tailAR = (meta.width || 1) / (meta.height || 1);
              const targetAR = targetWidth / targetHeight;

              let tailBuffer: Buffer;
              if (Math.abs(tailAR - targetAR) < 0.05) {
                tailBuffer = await resizeStrict(
                  tailOriginalBuffer,
                  targetWidth,
                  targetHeight
                );
              } else {
                // Try Gemini, fallback to Blur
                try {
                  tailBuffer = await resizeWithGemini(
                    tailOriginalBuffer,
                    targetWidth,
                    targetHeight
                  );
                } catch (e) {
                  tailBuffer = await resizeWithBlurFill(
                    tailOriginalBuffer,
                    targetWidth,
                    targetHeight
                  );
                }
              }

              klingTailUrl = await this.uploadToCloudinary(
                tailBuffer,
                `${postId}_kling_end`,
                params.userId,
                "Kling End",
                "image"
              );
              await airtableService.updatePost(postId, {
                generatedEndFrame: klingTailUrl,
              });
            } catch (e) {
              console.warn("Failed to process tail image, skipping.", e);
            }
          }
        } else if (params.imageReference) {
          klingInputUrl = getOptimizedUrl(params.imageReference);
          isImageToVideo = true;
        }

        // üõ†Ô∏è UPDATE: Always force PRO tier
        const tier = "pro";

        const endpointSuffix = isImageToVideo
          ? "image-to-video"
          : "text-to-video";
        const url = `${FAL_BASE_PATH}/${tier}/${endpointSuffix}`;

        const payload: any = {
          prompt: finalPrompt,
          duration: params.duration ? params.duration.toString() : "5",
          aspect_ratio: isPortrait ? "9:16" : "16:9",
        };

        if (isImageToVideo) {
          payload.image_url = klingInputUrl;
          // Only add tail URL if it exists (Pro model supports it)
          if (klingTailUrl) {
            payload.tail_image_url = klingTailUrl;
          }
        }

        const submitRes = await axios.post(url, payload, {
          headers: {
            Authorization: `Key ${FAL_KEY}`,
            "Content-Type": "application/json",
          },
        });
        externalId = submitRes.data.request_id;
        statusUrl = submitRes.data.status_url;
      }

      //OpenAi Branch
      else if (isOpenAI) {
        provider = "openai";
        const form = new FormData();
        form.append("prompt", finalPrompt);
        form.append("model", params.model || "sora-2-pro");
        form.append(
          "seconds",
          parseInt(params.duration?.toString().replace("s", "") || "4")
        );
        form.append("size", `${targetWidth}x${targetHeight}`);
        if (finalInputImageBuffer) {
          form.append("input_reference", finalInputImageBuffer, {
            filename: "ref.jpg",
            contentType: "image/jpeg",
          });
        }
        const genResponse = await axios.post(
          "https://api.openai.com/v1/videos",
          form,
          {
            headers: {
              ...form.getHeaders(),
              Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
            },
            timeout: VIDEO_UPLOAD_TIMEOUT,
          }
        );
        externalId = genResponse.data.id;
      }

      await airtableService.updatePost(postId, {
        generationParams: { ...params, externalId, statusUrl },
        mediaProvider: provider,
        status: "PROCESSING",
      });
      console.log(`‚úÖ Initiated ${provider} job: ${externalId}`);
    } catch (error: any) {
      console.error("‚ùå Video Gen Startup Failed:", error.message);
      await airtableService.updatePost(postId, {
        status: "FAILED",
        error: error.message,
        progress: 0,
      });
      await airtableService.refundUserCredit(params.userId, params.cost || 2);
    }
  },

  // ===========================================================================
  // 2. CHECK STATUS
  // ===========================================================================
  async checkPostStatus(post: Post) {
    const params = post.generationParams as any;
    if (post.status !== "PROCESSING" || !params?.externalId) return;
    const externalId = params.externalId;
    const provider = post.mediaProvider || "openai";
    const userId = post.userId;

    try {
      let isComplete = false;
      let isFailed = false;
      let finalUrl = "";
      let progress = post.progress || 0;
      let errorMessage = "";

      if (provider.includes("kie")) {
        const checkRes = await axios.get(
          `${KIE_BASE_URL}/jobs/recordInfo?taskId=${externalId}`,
          { headers: { Authorization: `Bearer ${KIE_API_KEY}` } }
        );
        if (checkRes.data.data.state === "success") {
          const resJson = JSON.parse(checkRes.data.data.resultJson);
          finalUrl = resJson.resultUrls?.[0] || resJson.videoUrl;
          isComplete = true;
        } else if (checkRes.data.data.state === "fail") {
          isFailed = true;
          errorMessage = checkRes.data.data.failMsg;
        } else progress = Math.min(95, progress + 5);
      } else if (provider.includes("kling")) {
        const checkUrl =
          params.statusUrl || `${FAL_BASE_PATH}/requests/${externalId}/status`;
        const statusRes = await axios.get(checkUrl, {
          headers: { Authorization: `Key ${FAL_KEY}` },
        });
        if (statusRes.data.status === "COMPLETED") {
          const resultRes = await axios.get(statusRes.data.response_url, {
            headers: { Authorization: `Key ${FAL_KEY}` },
          });
          finalUrl = resultRes.data.video.url;
          isComplete = true;
        } else if (statusRes.data.status === "FAILED") {
          isFailed = true;
          errorMessage = statusRes.data.error;
        } else progress = Math.min(90, progress + 5);
      } else if (provider.includes("openai")) {
        // (OpenAI logic omitted for brevity, assume unchanged)
      }

      if (isComplete && finalUrl) {
        const cloudUrl = await this.uploadToCloudinary(
          finalUrl,
          post.id,
          userId,
          "Video",
          "video"
        );
        await this.finalizePost(post.id, cloudUrl, provider, userId);
      } else if (isFailed) {
        await airtableService.updatePost(post.id, {
          status: "FAILED",
          error: errorMessage,
          progress: 0,
        });
        const costToRefund = params?.cost || 5;
        await airtableService.refundUserCredit(userId, costToRefund);
      } else {
        if (progress !== post.progress)
          await airtableService.updatePost(post.id, { progress });
      }
    } catch (error: any) {
      console.error(`Check Status Error (${post.id}):`, error.message);
    }
  },

  async finalizePost(
    postId: string,
    url: string,
    provider: string,
    userId: string
  ) {
    await airtableService.updatePost(postId, {
      mediaUrl: url,
      mediaProvider: provider,
      status: "READY",
      progress: 100,
      generationStep: "COMPLETED",
    });
    await ROIService.incrementMediaGenerated(userId);
  },

  // ===========================================================================
  // 3. CREATIVE WORKFLOWS (Image/Carousel) - FIXED
  // ===========================================================================

  // üì∏ IMAGE GENERATION: Update Post (Timeline)
  async startImageGeneration(postId: string, finalPrompt: string, params: any) {
    console.log(
      `üé® Gemini 3 Pro Gen for Post ${postId} | AR: ${params.aspectRatio}`
    );
    try {
      const refUrls =
        params.imageReferences ||
        (params.imageReference ? [params.imageReference] : []);
      const refBuffers = await this.downloadAndOptimizeImages(refUrls);

      // üõ†Ô∏è FIX 1: Normalize Aspect Ratio for Gemini
      let targetRatio: "16:9" | "9:16" | "1:1" = "16:9";
      const ar = params.aspectRatio;

      if (ar === "1:1" || ar === "square") targetRatio = "1:1";
      else if (ar === "9:16" || ar === "portrait") targetRatio = "9:16";
      else if (ar === "16:9" || ar === "landscape") targetRatio = "16:9";

      const buf = await GeminiService.generateOrEditImage({
        prompt: finalPrompt,
        aspectRatio: targetRatio,
        referenceImages: refBuffers,
        modelType: "quality",
        useGrounding: true,
      });

      const cloudUrl = await this.uploadToCloudinary(
        buf,
        postId,
        params.userId,
        "Gemini 3 Pro Image",
        "image"
      );

      await this.finalizePost(postId, cloudUrl, "gemini-3-pro", params.userId);
    } catch (e: any) {
      console.error("Image Gen Error:", e);
      await airtableService.updatePost(postId, {
        status: "FAILED",
        error: e.message,
        progress: 0,
      });
      await airtableService.refundUserCredit(params.userId, 1);
    }
  },

  // üé† CAROUSEL GENERATION: Update Post (Timeline)
  async startCarouselGeneration(
    postId: string,
    finalPrompt: string,
    params: any
  ) {
    console.log(`üé† Gemini 3 Pro Carousel for Post ${postId}`);
    try {
      const imageUrls: string[] = [];
      const userRefBuffers = await this.downloadAndOptimizeImages(
        params.imageReferences || []
      );
      const carouselHistory: Buffer[] = [...userRefBuffers];

      // üõ†Ô∏è FIX 2: Apply Aspect Ratio to Carousel too
      let targetRatio: "16:9" | "9:16" | "1:1" = "9:16"; // Default vertical
      const ar = params.aspectRatio;
      if (ar === "1:1" || ar === "square") targetRatio = "1:1";
      else if (ar === "16:9" || ar === "landscape") targetRatio = "16:9";
      else if (ar === "9:16" || ar === "portrait") targetRatio = "9:16";

      const steps = [
        "Image 1: Establish the scene. ",
        "Image 2: Action or Detail. ",
        "Image 3: Conclusion. ",
      ];

      for (let i = 0; i < steps.length; i++) {
        const stepPrompt = `
        PROJECT: Visual Story Carousel.
        SLIDE: ${i + 1}/3.
        THEME: ${finalPrompt}
        FOCUS: ${steps[i]}
        CONSTRAINT: Maintain perfect visual consistency with previous images.
        `;

        const buf = await GeminiService.generateOrEditImage({
          prompt: stepPrompt,
          aspectRatio: targetRatio,
          referenceImages: carouselHistory,
          modelType: "quality",
        });

        carouselHistory.push(buf);

        const url = await this.uploadToCloudinary(
          buf,
          `${postId}_slide_${i + 1}`,
          params.userId,
          `Slide ${i + 1}`,
          "image"
        );
        imageUrls.push(url);
      }

      await airtableService.updatePost(postId, {
        mediaUrl: JSON.stringify(imageUrls),
        mediaProvider: "gemini-3-carousel",
        status: "READY",
        progress: 100,
        generationStep: "COMPLETED",
      });
      await ROIService.incrementMediaGenerated(params.userId);
    } catch (e: any) {
      console.error("Carousel Error:", e);
      await airtableService.updatePost(postId, {
        status: "FAILED",
        error: e.message,
        progress: 0,
      });
      await airtableService.refundUserCredit(params.userId, 3);
    }
  },

  async downloadAndOptimizeImages(urls: string[]): Promise<Buffer[]> {
    if (urls.length === 0) return [];
    const promises = urls.map(async (rawUrl) => {
      try {
        const url = getOptimizedUrl(rawUrl);
        const res = await axios.get(url, { responseType: "arraybuffer" });
        return await sharp(res.data)
          .resize(1024, 1024, { fit: "inside" })
          .toFormat("jpeg", { quality: 80 })
          .toBuffer();
      } catch (e) {
        return null;
      }
    });
    const results = await Promise.all(promises);
    return results.filter((buf): buf is Buffer => buf !== null);
  },

  async uploadToCloudinary(
    f: any,
    p: string,
    u: string,
    t: string,
    r: string
  ): Promise<string> {
    return new Promise<string>((resolve, reject) => {
      const options = {
        resource_type: r as "auto" | "image" | "video" | "raw",
        folder: `visionlight/user_${u}/${r}s`,
        public_id: p,
        overwrite: true,
        context: { caption: t, alt: t },
      };
      if (Buffer.isBuffer(f))
        cloudinary.uploader
          .upload_stream(options, (err, res) =>
            err ? reject(err) : resolve(res!.secure_url)
          )
          .end(f);
      else
        cloudinary.uploader.upload(f, options, (err, res) =>
          err ? reject(err) : resolve(res!.secure_url)
        );
    });
  },
};
